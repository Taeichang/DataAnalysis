{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Taeichang/DataAnalysis/blob/main/%EC%98%A4%ED%94%88%EC%86%8C%EC%8A%A4_%EB%8D%B0%EC%9D%B4%ED%84%B0_%EB%B6%84%EC%84%9D_4%EA%B0%95.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# 오픈소스 기반 데이터 분석 4강 - 데이터 수집\n"
      ],
      "metadata": {
        "id": "DkPKaAsoRq5Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 데이터 수집 방법\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_-c-RHQiBSg4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3.1 파일\n",
        "\n",
        "* 로컬 환경이나 네트워크 저장소에 저장된 다양한 형태의 파일에서 데이터를 읽어 분석에 활용\n",
        "* 정형, 비정형, 반정형 데이터 모두 수집 가능\n",
        "* 일회성 분석이나 배치(batch) 처리 방식에 적합\n",
        "* Pandas 라이브러리:\n",
        "    * 다양한 소스의 데이터를 통합된 방식으로 처리할 수 있는 기능 제공\n",
        "    * 표 형태의 DataFrame으로 변환하여 구조화된 형태로 다룰 수 있게 함\n",
        "* DataFrame은 레이블이 있는 다차원 데이터 구조. 다양한 데이터 조작, 정제, 분석 기능을 제공"
      ],
      "metadata": {
        "id": "-I7BVVlnRrB0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1) CSV (Comma-Separated Values)\n",
        "\n",
        "* 쉼표로 구분된 텍스트 데이터 파일로 표 형태의 데이터를 저장하는 데 주로 사용\n",
        "* 높은 범용성이 서로 다른 시스템/플렛폼 간에 데이터 교환 용이\n",
        "* 평면적 구조만 지원\n",
        "* 순수한 텍스트 형식으로만 데이터 저장, 바이너리 데이터는 직접 저장 불가\n",
        "* 데이터 타입에 대한 명시적 정보 불포함, 숫자와 문자열 구분 추가 처리 필요\n",
        "* Pandas 라이브러리의 read_csv() 메서드를 통해 DataFrame으로 읽어올 수 있음. 서로 다른 자료형의 데이터를 동일한 표 안에 담을 수 있음."
      ],
      "metadata": {
        "id": "n_JjUcyEA2vw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   sep: 구분자 지정. 기본적으로 쉼표지만 탭이나 다른 기호 설정 가능\n",
        "*   header: 열 이름으로 사용할 행 번호를 지정. None으로 설정하면 열 이름 없이 데이터로 처리\n",
        "* index_col: 인덱스로 사용할 열 번호 / 열 이름 지정\n",
        "* skiprows: 파일 상위의 n개 행을 건너뛰고 읽기\n",
        "* nrows: 읽어 올 행의 개수 제한\n",
        "* encoding: 한글 파일의 경우 주로 utf-8 이나 cp949 사용\n",
        "\n"
      ],
      "metadata": {
        "id": "h6-edyCzk79C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## data.csv 파일 읽기\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('data.csv', encoding = 'utf-8', sep = ',', header = 0, index_col = None, skiprows = None, nrows = None)\n",
        "print(df)"
      ],
      "metadata": {
        "id": "2Y2HEiaiRwAI",
        "outputId": "404870dd-9087-4e44-d20d-cf54a45e83dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           날짜    체중  골격근량  체지방량\n",
            "0  2025.02.06  64.7  30.0  11.1\n",
            "1  2025.02.04  64.0  29.3  11.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2) JSON(JavaScript Object Notation)\n",
        "\n",
        "* JavaScript 객체 표기법을 따르는 텍스트 데이터 파일, 반정형 데이터 저장\n",
        "* 텍스트 기반이면서도 구조화된 형태, 프로그램 간 데이터 교환 용이\n",
        "* 키와 값 형태로 이루어진 데이터 포멧\n",
        "* 중첩된 구조 표현 가능\n",
        "* 데이터 모델이 자주 변경되거나 확장되는 환경에서 유용\n",
        "* 데이터 검색이 직관적이지 않을 수 있음\n",
        "* 데이터를 읽어올 때 json.load()\n",
        "* 문자열 데이터 읽어올 때 json.loads()\n",
        "* Pandas 라이브러리의 read_json() 메서드를 통해 DataFrame으로 읽어올 수 있음."
      ],
      "metadata": {
        "id": "9kHCFaGlRrE0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   JSON 데이터는 저장 방식에 따라 구조가 다름, Pandas의 read_json()은 이런 구조적 차이에 대응하기 위해 orient라는 파라미터를 제공\n",
        "* orient: JSON 데이터가 어떤 형태로 저장되어 있는지 알려줌\n",
        "    * records - 리스트 안에 딕셔너리 형태\n",
        "    * columns - 열 이름이 키가 되고, 각 열의 값들이 리스트로 표현\n",
        "*   JSON Lines: 각 줄이 하나의 JSON 객체로 구성\n",
        "\n"
      ],
      "metadata": {
        "id": "y9tqXhbsoB55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# JSON 데이터 처리와 분석에 필요한 라이브러리 불러옴\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# json.load(f) 사용해 파일 내용을 파이썬 객체(리스트/딕셔너리)로 변환\n",
        "with open('data.json', mode='r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "## data.json 파일 출력\n",
        "print(data)\n",
        "\n",
        "# pd.read_json 사용해 JSON 파일을 바로 DataFrame으로 읽음 -> 관계형 데이터베이스의 테이블\n",
        "df = pd.read_json('data.json', orient = 'records', encoding = 'utf-8',lines = False)\n",
        "\n",
        "print(df)"
      ],
      "metadata": {
        "id": "IO8bsKekR0W_",
        "outputId": "dba196fb-3ec8-4fa7-dcfa-897b94f29fdb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'매출데이터': [{'월': '2025-01', '매출액': 1000000, '비용': 700000, '이익': 300000}, {'월': '2025-02', '매출액': 1200000, '비용': 800000, '이익': 400000}, {'월': '2025-03', '매출액': 1500000, '비용': 900000, '이익': 600000}]}\n",
            "                                               매출데이터\n",
            "0  {'월': '2025-01', '매출액': 1000000, '비용': 700000,...\n",
            "1  {'월': '2025-02', '매출액': 1200000, '비용': 800000,...\n",
            "2  {'월': '2025-03', '매출액': 1500000, '비용': 900000,...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3) 텍스트 파일(TXT, LOG 등)\n",
        "\n",
        "교재 p. 109 - 110\n",
        "\n",
        "*   비정형 데이터를 저장하고 활용\n",
        "* 전처리 과정에서 텍스트 정제, 패턴 추출, 토큰화 같은 추가적인 작업이 필수\n",
        "*   특정한 표준 형식 없이 자유로운 형태, 특정 데이터를 추출하기 위해 정규표현식(regular expression) 사용\n",
        "\n"
      ],
      "metadata": {
        "id": "uLd_3A_IRrHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# with open() 구문을 사용해 내용을 읽고 문자열로 저장함\n",
        "with open('callcenter20250301.log', 'r', encoding='utf-8') as f:\n",
        "    content = f.read()\n",
        "\n",
        "# 주민등록번호 패턴 생성 (re.compile 패턴을 컴파일하여 패턴 객체를 반환. 이후 검색이나 추출 시 활용)\n",
        "pattern = re.compile(r'(\\d{6})-(\\d{7})')\n",
        "\n",
        "# 주민등록번호 마스킹 (pattern.sub 검출해낸 정보를 변조시켜 마스킹, 특정 패턴 있을 경우 변조)\n",
        "masked_content = pattern.sub(r'\\1-*******', content)\n",
        "\n",
        "# 마스킹된 파일(callcenter20250301_masked.log) 오픈 및 쓰기\n",
        "# 원본 데이터 보존 & 마스킹 데이터 별도 확보\n",
        "with open('callcenter20250301_masked.log', mode='w') as f:\n",
        "        f.write(masked_content)\n",
        "\n",
        "print(\"주민등록번호 마스킹 완료. 'callcenter20250301_masked.log.txt' 파일로 저장되었습니다.\")"
      ],
      "metadata": {
        "id": "60qOf7uxVdAg",
        "outputId": "c2e04e3b-4e78-4792-a562-7b067337a690",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "주민등록번호 마스킹 완료. 'callcenter20250301_masked.log.txt' 파일로 저장되었습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3.2 API"
      ],
      "metadata": {
        "id": "Sfyf5ul2BzAA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2) Requests 라이브러리\n",
        "\n",
        "* HTTP 프로토콜을 사용하여 웹 서버와 통신할 때 활용되는 파이썬 라이브러리\n",
        "* 직관적인 문법과 간결한 코드\n",
        "* 사람이 직접 클릭하는 것이 아닌 프로그램적으로 자동화 가능 (대량의 데이터 수집/주기적으로 갱신 되는 데이터)\n",
        "* HTTP 요청 방식\n",
        "    * GET 방식: 서버에서 데이터를 가져올 때\n",
        "    * POST 방식: 서버레 데이터를 전송/특정 작업을 요청할 때\n",
        "    * PUT, DELETE, HEAD\n",
        "* 서버에서 반환한 응답 데이터를 다양한 형태로 처리할 수 있음\n",
        "    * response.json() - 파이썬 딕셔너리 형식으로 변환\n",
        "    * response.txt - 문자열 형태로 내용을 확인 가능"
      ],
      "metadata": {
        "id": "eOMufu5SXiAU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   .get(위치 url, 어떤 인자값), 결과는 객체\n",
        "*   timeout 설정, 응답 5초 이상 시 요청 중단 설정\n",
        "*  .raise_for_status()\n",
        "    * 정상적 응답 반환 시. JSON 형식의 응답 데이터를 파이썬의 딕셔너리로 변환\n",
        "    * 응답 상태 코드(status code) 확인\n",
        "    * 상태값에 오류가 있을 때 알려줌\n",
        "    * 상태값 200(정상) 아닌 경우, HTTP 오류가 발생한 것으로 간주하여 예외 발생\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wlbq3yU-6iIq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests ##requests lib로 파이썬에서 정보를 갖고 옴\n",
        "import json ##json lib 통해 파이썬 객체로 변환\n",
        "\n",
        "# API 요청 대상이 되는 URL 설정\n",
        "url = \"https://api.open-meteo.com/v1/forecast?=&=&current=temperature_2m\"\n",
        "\n",
        "# 함께 전송할 정보를 딕셔너리로 생성\n",
        "params = {\n",
        "    \"latitude\": \"37.58638333\",\n",
        "    \"longitude\": \"127.0203333\",\n",
        "    \"current\": \"temperature_2m\"\n",
        "}\n",
        "\n",
        "# try문을 이용하여 API 요청을 보냄, 발생할 수 있는 예외 상황 처리\n",
        "try:\n",
        "    # URL과 파라미터 함께 전달\n",
        "    response = requests.get(url, params = params, timeout = 5)\n",
        "    response.raise_for_status()\n",
        "\n",
        "    # JSON 데이터 읽기\n",
        "    data = response.json()\n",
        "\n",
        "    print(\"API 응답:\", data)\n",
        "    #f문자열로 바꾸기\n",
        "    print(\"서울시 종로구의 현재 온도는 : {0}{1} 입니다.\".format(data['current']['temperature_2m'], data['current_units']['temperature_2m']))\n",
        "\n",
        "# 네트워크/서버 오류\n",
        "except requests.exceptions.RequestException as e:\n",
        "    print(f\"API 호출 실패: {e}\")\n",
        "\n",
        "# 데이터 손상/JSON형식 아닐 경우\n",
        "except json.JSONDecodeError as e:\n",
        "    print(f\"JSON 파싱 실패: {e}\")"
      ],
      "metadata": {
        "id": "JpmgdsW9V0CY",
        "outputId": "2cfd37ac-ffea-44be-c1ed-6dd3b8c3d0d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API 응답: {'latitude': 37.6, 'longitude': 127.0, 'generationtime_ms': 0.024080276489257812, 'utc_offset_seconds': 0, 'timezone': 'GMT', 'timezone_abbreviation': 'GMT', 'elevation': 29.0, 'current_units': {'time': 'iso8601', 'interval': 'seconds', 'temperature_2m': '°C'}, 'current': {'time': '2025-10-09T08:45', 'interval': 900, 'temperature_2m': 19.3}}\n",
            "서울시 종로구의 현재 온도는 : 19.3°C 입니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.3.3 웹 스크래핑\n",
        "\n",
        "* 웹 크롤링(web crawling): 자동화된 방식으로 웹 페이지를 방문, 링크를 따라 이동, 웹의 구조 탐색하는 과정에서 모든 데이처 수집/인덱싱\n",
        "* 웹 스크레핑(web scraping)\n",
        "    * 특정 웹 페이지에서 원하는 데이터만 선택적으로 추출\n",
        "    * 고려사항\n",
        "        * 웹 페이지 구조 분석\n",
        "        * 데이터 추출 방법\n",
        "        * 웹 사이트 정책 준수\n",
        "        * 정적 페이지(HTML로만 구성)와 동적 페이지(JavaScript 등 콘텐츠가 변경되는 페이지)\n",
        "    "
      ],
      "metadata": {
        "id": "7ww8whoXCoU4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 데이터 스크래핑\n",
        "\n",
        "* Selenium\n",
        "    * 웹 브라우저를 실제로 실행, 사람이 클릭하고 입력하는 것처럼 자동으로 조작\n",
        "    * WebDriver는 Selenium이 브라우저를 조작할 수 있도록 연결해 주는 프로그램\n",
        "    * Selenium 코드가 실행될 때 WebDriver가 웹 브라우저를 띄우고 그 위에서 자동화 작업이 이루어짐\n",
        "\n",
        "* lxml\n",
        "    * HTML과 XML 문서를 효과적으로 읽고, 특정 정보 추출, 문서 수정/생성\n",
        "    * 뛰어난 성능(C 기반)과 사용 편의성\n",
        "    * 효율적으로 파싱\n",
        "    * 데이터를 읽어 문서 객체로 변환 후 트리 구조로 쉽게 접근"
      ],
      "metadata": {
        "id": "RLfPaa1ZiqIC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Selenium과 lxml을 이용한 웹 스크래핑\n",
        "!curl -o google-chrome-stable_current_amd64.deb https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n",
        "!apt install ./google-chrome-stable_current_amd64.deb -y\n",
        "!pip install selenium webdriver_manager"
      ],
      "metadata": {
        "id": "79dmM7MNk8pB",
        "outputId": "7f5892c1-5639-4704-efb3-09961a329e02",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  114M  100  114M    0     0  80.2M      0  0:00:01  0:00:01 --:--:-- 80.2M\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "Note, selecting 'google-chrome-stable' instead of './google-chrome-stable_current_amd64.deb'\n",
            "The following additional packages will be installed:\n",
            "  libvulkan1 mesa-vulkan-drivers\n",
            "The following NEW packages will be installed:\n",
            "  google-chrome-stable libvulkan1 mesa-vulkan-drivers\n",
            "0 upgraded, 3 newly installed, 0 to remove and 38 not upgraded.\n",
            "Need to get 10.9 MB/131 MB of archives.\n",
            "After this operation, 448 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libvulkan1 amd64 1.3.204.1-2 [128 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 mesa-vulkan-drivers amd64 23.2.1-1ubuntu3.1~22.04.3 [10.7 MB]\n",
            "Get:3 /content/google-chrome-stable_current_amd64.deb google-chrome-stable amd64 141.0.7390.76-1 [121 MB]\n",
            "Fetched 10.9 MB in 2s (4,640 kB/s)\n",
            "Selecting previously unselected package libvulkan1:amd64.\n",
            "(Reading database ... 126675 files and directories currently installed.)\n",
            "Preparing to unpack .../libvulkan1_1.3.204.1-2_amd64.deb ...\n",
            "Unpacking libvulkan1:amd64 (1.3.204.1-2) ...\n",
            "Selecting previously unselected package google-chrome-stable.\n",
            "Preparing to unpack .../google-chrome-stable_current_amd64.deb ...\n",
            "Unpacking google-chrome-stable (141.0.7390.76-1) ...\n",
            "Selecting previously unselected package mesa-vulkan-drivers:amd64.\n",
            "Preparing to unpack .../mesa-vulkan-drivers_23.2.1-1ubuntu3.1~22.04.3_amd64.deb ...\n",
            "Unpacking mesa-vulkan-drivers:amd64 (23.2.1-1ubuntu3.1~22.04.3) ...\n",
            "Setting up libvulkan1:amd64 (1.3.204.1-2) ...\n",
            "Setting up mesa-vulkan-drivers:amd64 (23.2.1-1ubuntu3.1~22.04.3) ...\n",
            "Setting up google-chrome-stable (141.0.7390.76-1) ...\n",
            "update-alternatives: using /usr/bin/google-chrome-stable to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/google-chrome-stable to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/google-chrome-stable to provide /usr/bin/google-chrome (google-chrome) in auto mode\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.8) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libumf.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_opencl.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtcm_debug.so.1 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero_v2.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_adapter_level_zero.so.0 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libhwloc.so.15 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libur_loader.so.0 is not a symbolic link\n",
            "\n",
            "Collecting selenium\n",
            "  Downloading selenium-4.36.0-py3-none-any.whl.metadata (7.5 kB)\n",
            "Collecting webdriver_manager\n",
            "  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: urllib3<3.0,>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (2.5.0)\n",
            "Collecting trio<1.0,>=0.30.0 (from selenium)\n",
            "  Downloading trio-0.31.0-py3-none-any.whl.metadata (8.5 kB)\n",
            "Collecting trio-websocket<1.0,>=0.12.2 (from selenium)\n",
            "  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: certifi>=2025.6.15 in /usr/local/lib/python3.12/dist-packages (from selenium) (2025.8.3)\n",
            "Requirement already satisfied: typing_extensions<5.0,>=4.14.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (4.15.0)\n",
            "Requirement already satisfied: websocket-client<2.0,>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from webdriver_manager) (2.32.4)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from webdriver_manager) (1.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from webdriver_manager) (25.0)\n",
            "Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.30.0->selenium) (25.3.0)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.30.0->selenium) (2.4.0)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.30.0->selenium) (3.10)\n",
            "Collecting outcome (from trio<1.0,>=0.30.0->selenium)\n",
            "  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.30.0->selenium) (1.3.1)\n",
            "Collecting wsproto>=0.14 (from trio-websocket<1.0,>=0.12.2->selenium)\n",
            "  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (1.7.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->webdriver_manager) (3.4.3)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from wsproto>=0.14->trio-websocket<1.0,>=0.12.2->selenium) (0.16.0)\n",
            "Downloading selenium-4.36.0-py3-none-any.whl (9.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n",
            "Downloading trio-0.31.0-py3-none-any.whl (512 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.7/512.7 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
            "Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
            "Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: wsproto, outcome, webdriver_manager, trio, trio-websocket, selenium\n",
            "Successfully installed outcome-1.3.0.post0 selenium-4.36.0 trio-0.31.0 trio-websocket-0.12.2 webdriver_manager-4.0.2 wsproto-1.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from selenium import webdriver\n",
        "from selenium.webdriver.chrome.service import Service as ChromeService\n",
        "from webdriver_manager.chrome import ChromeDriverManager\n",
        "from selenium.webdriver.common.by import By\n",
        "from lxml import html\n",
        "import time\n",
        "\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')               # 웹 브라우저 창 없이 보이지 않게 설정\n",
        "chrome_options.add_argument('--no-sandbox')             # 보안모드 비활성화 (Colab 필수)\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')  # 메모리 부족 방지 (Colab 필수)\n",
        "chrome_options.add_argument('--window-size=1920x1080')  # 창 크기 설정(가상)\n",
        "chrome_options.add_argument('--disable-gpu')            # GPU 가속 비활성화 (일부 환경 안정성)\n",
        "chrome_options.binary_location = \"/usr/bin/google-chrome-stable\"  # Colab에서 Chrome 실행 경로와 드라이버 경로를 명시적으로 설정해야 함\n",
        "\n",
        "# 드라이버 실행\n",
        "driver = webdriver.Chrome(options = chrome_options)\n",
        "\n",
        "# 사이트 접속\n",
        "url = 'https://www.naver.com/'\n",
        "driver.get(url) #눈에 보이지 않지만 접속됨\n",
        "\n",
        "# 사이트 접속 대기 지연 2초, 없으면 정상적으로 스크랩핑이 안 될 때도 있음\n",
        "time.sleep(2)\n",
        "\n",
        "# 페이지 제목 출력\n",
        "page_source = driver.page_source\n",
        "# 페이지 자체를 html로 받음. 이를 트리 형태로 바꿈\n",
        "tree = html.fromstring(page_source)\n",
        "\n",
        "try:\n",
        "    #.xpath 특정 요소 갖고옴\n",
        "    title_text = tree.xpath('//title/text()')\n",
        "    print('웹 페이지 제목 (XPath): ', title_text[0] if title_text else '제목 없음')\n",
        "except Exception as e:\n",
        "    print(f'XPath 추출 실패: {e}')\n",
        "\n",
        "# 드라이버 종료\n",
        "driver.quit()"
      ],
      "metadata": {
        "id": "cRC8x3_iW0im",
        "outputId": "794b64d6-fe04-42f5-d1b8-8408762187b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "웹 페이지 제목 (XPath):  NAVER\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# 실습 시나리오"
      ],
      "metadata": {
        "id": "Bu6OMZyGirOq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 공공데이터 포털 가입 및 데이터 신청\n",
        "\n",
        "- [https://www.data.go.kr](https://www.data.go.kr)\n",
        "- 한국환경공단 에어코리아 대기오염정보 데이터 신청"
      ],
      "metadata": {
        "id": "nsuqRN9RkZlW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "## 데이터 수집 url 및 api key 설정\n",
        "\n",
        "##1:06\n",
        "\n",
        "params = {\n",
        "    'serviceKey': api_key,\n",
        "    'returnType': 'json',\n",
        "    'numOfRows': '100',\n",
        "    'pageNo': '1',\n",
        "    'sidoName': '서울',\n",
        "    'ver': '1.0'\n",
        "} ##para 어떻게 설정해야하는지 문서 제공\n",
        "\n",
        "## 데이터 수집\n",
        "\n",
        "## 호출 성공/실패 출력\n",
        "\n"
      ],
      "metadata": {
        "id": "7yCozmQeXJcO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}